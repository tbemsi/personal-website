<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title> Profile Regression vs other clustering methods on synthetic data - Bemsibom Toh </title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="referrer" content="no-referrer">
    <meta name="description" content="" />
    <meta property="og:site_name" content="Bemsibom Toh" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://bemsibomtoh.com/blog/paulo/" />
    <meta property="og:title" content="Profile Regression vs other clustering methods on synthetic data" />
    <meta property="og:image" content="https://bemsibomtoh.com/image/avatar.jpg" />
    <meta property="og:description" content="" />

    <meta name="twitter:card" content="summary_large_image" />
    
    <meta name="twitter:site" content="@tbemsi">
    <meta name="twitter:creator" content="@tbemsi">
    
    <meta name="twitter:title" content="Profile Regression vs other clustering methods on synthetic data" />
    <meta name="twitter:description" content="" />
    <meta name="twitter:image" content="https://bemsibomtoh.com/image/avatar.jpg" />

    <link rel="canonical" href="https://bemsibomtoh.com/blog/paulo/">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha256-aAr2Zpq8MZ+YA/D6JtRD3xtrwpEz2IqOS+pWD/7XKIw=" crossorigin="anonymous" />

    <link rel="stylesheet" href="https://bemsibomtoh.com/css/custom.css" />

    
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/styles/tomorrow.min.css" integrity="sha256-0QU8ry64q+N6YBIEF/6XF6vUeF15gbNO4tLS6ikk0FI=" crossorigin="anonymous" />
    

    

    <link rel="shortcut icon"
        href="https://bemsibomtoh.com/image/favicon.png">

    
        <link href="https://bemsibomtoh.com/index.xml" rel="alternate" type="application/rss+xml" title="Bemsibom Toh" />
    
</head>

<body>
    
    <div class="my-4 my-md-5 header">
    <div class="container">
        <div class="row">
            <div class="col-auto offset-md-1 d-none d-md-block">
                
                    <a href="https://bemsibomtoh.com/">
                        <img class="ml-md-4 logo img-fluid d-block rounded-circle" src="https://bemsibomtoh.com/image/avatar.jpg" alt="logo">
                    </a>
                
            </div>
            <div class="col-auto align-self-center mr-auto">
                <a href="https://bemsibomtoh.com/">
                    <h1 class="name">Bemsibom Toh</h1>
                </a>

                <ul class="nav nav-primary">
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-about" href="https://bemsibomtoh.com/">
                                
                                About
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-blog" href="https://bemsibomtoh.com/blog/">
                                
                                Blog
                            </a>
                        </li>
                    

                    
                </ul>

            </div>
        </div>
    </div>
</div>


    <div class="content">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-sm-12 col-md-10">
                    <h1 class="mx-0 mx-md-4 blog-post-title">Profile Regression vs other clustering methods on synthetic data</h1>

                    <div class="mb-md-4 meta">
                        
                            
                                <span class="author" title="Bemsibom Toh">
                                    Bemsibom Toh
                                </span>
                            
                        

                        <span class="date middot" title='Wed Dec 16 2020 00:00:00 UTC'>
                            2020-12-16
                        </span>

                        <span class="reading-time middot">
                            7 minute read
                        </span>

                        <div class="d-none d-md-inline tags">
                            <ul class="list-unstyled d-inline">
                                
                            </ul>
                        </div>

                        <div class="d-none d-md-inline tags">
                            <ul class="list-unstyled d-inline">
                                
                                
                            </ul>
                        </div>
                    </div>

                    <div class="markdown">
                        
    
<link href="https://bemsibomtoh.com/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="https://bemsibomtoh.com/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Profile regression is a clustering technique which links the clusters to an outcome of interest via a regression model. It differs from traditional distance-based clustering techniques in that it uses a stochastic model-based approach.</p>
<p>In general, models are fitted using Markov Chain Monte Carlo sampling methods, which outputs a different partition of the data at each iteration of the sampler.</p>
<p>The aim of this article is to compare the performance of profile regression to other clustering methods, such as Hierarchical clustering, K-Means, K-mode and Latent Class Analysis. We will do this by applying profile regression to a set of 1000 simulated datasets, generated from code written by <a href="https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/lnichols/">Linda Nichols</a> and <a href="https://research.birmingham.ac.uk/portal/en/persons/thomas-taverner(68156dc8-5825-4005-8f6c-559fcbf6717f).html">Tom Taverner</a>. The mathematical model used to generate these datasets will be the subject of another article.</p>
<p>We begin by loading the datasets and libraries we need as follows:</p>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(data.table)
library(ggplot2)
library(lpSolve)
library(viridisLite)
library(viridis)
library(hrbrthemes)
hrbrthemes::import_roboto_condensed()</code></pre>
<pre><code>## You will likely need to install these fonts on your system as well.
## 
## You can find them in [/Library/Frameworks/R.framework/Versions/4.0/Resources/library/hrbrthemes/fonts/roboto-condensed]</code></pre>
<pre class="r"><code>library(mclust)</code></pre>
<pre><code>## Package &#39;mclust&#39; version 5.4.6
## Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications.</code></pre>
<pre class="r"><code>library(mcclust)
library(coda)
library(PReMiuM)
source(&#39;/Users/bemsi/Documents/BSU/code/transform_bham_data.R&#39;)</code></pre>
<p>Next we load the different datasets we will use for this project:</p>
<pre class="r"><code>setwd(&#39;/Users/bemsi/Documents/BSU/code/&#39;)
birmingham.aris &lt;- get(load(&#39;/Users/bemsi/Documents/BSU/code/sim_20201009_ri.RData&#39;)) #ARIs from the other methods

#profile regression with no outcome
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/SimulationOutputNoOutcome&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE) 
premium.aris.no.outcome &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

#profile regression with random outcome
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/SimulationOutputRandomOutcome&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE)
premium.aris.random.outcome &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

#profile regression with deterministic outcome
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/SimulationOutputDetOutcome&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE)
premium.aris.det.outcome &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

#profile regression with semi-deterministic outcome 1
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/DetOutcomeOne&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE)
premium.aris.det.outcome.1 &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

#profile regression with semi-deterministic outcome 2
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/DetOutcomeThree&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE)
premium.aris.det.outcome.2 &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

# Load and transform the first dataset in the bank of simulated datasets
birmingham.dfs &lt;- get(load(&#39;/Users/bemsi/Documents/BSU/code/sim_20201009_df.rData&#39;))
sample.dataframe &lt;- birmingham.dfs[[1]]
inputs &lt;- transform_bham_data.one(sample.dataframe)

#modifying original dataframe
birmingham.aris$PRegr &lt;- premium.aris.no.outcome$V1
birmingham.aris.one &lt;- reshape2::melt(birmingham.aris , measure.vars=c(&quot;LCA&quot;, &quot;kmode&quot;, &quot;HCA&quot;, &quot;MCAkm&quot;, &quot;kmean&quot;, &quot;PRegr&quot;))
names(birmingham.aris.one) &lt;- c(&quot;Method&quot;, &quot;ARI&quot;)</code></pre>
<p>We now visualize the data, to see whether there is any apparent clustering structure in it.</p>
<pre class="r"><code>clusters &lt;- data.frame(inputs$inputData$group)
colnames(clusters) &lt;- &quot;Cluster&quot;
pheatmap::pheatmap(inputs$inputData[2:27],  
                   cluster_rows = F,
                   cluster_cols = F,
                   show_rownames = FALSE,
                   legend = FALSE,
                   cutree_rows = 4, 
                   col = c(&quot;white&quot;, &quot;black&quot;),
                   annotation_row = clusters)</code></pre>
<p><img src="https://bemsibomtoh.com/blog/Paulo_files/figure-html/visualizeData-1.png" width="672" /></p>
<p>We can see that there is some structure in the dataset, and there are three clearly identifiable clusters in the dataset, as well as one ‘noisy’ cluster.</p>
</div>
<div id="no-outcome" class="section level1">
<h1>No outcome</h1>
<p>We begin by looking at the output of profile regression when there is no supervision - i.e., we carry out profile regression with no outcome to guide the clustering algorithm.</p>
<div id="convergence-analysis" class="section level2">
<h2>Convergence analysis</h2>
<p>We will use three methods to assess convergence of the profile regression algorithm: a visual method using traceplots of certain parameters, the <a href="https://www.rdocumentation.org/packages/coda/versions/0.19-4/topics/gelman.diag">Gelman Diagnostic</a>, and the <a href="https://www.rdocumentation.org/packages/coda/versions/0.19-4/topics/geweke.diag">Geweke Diagnostic</a>.</p>
<p>We begin by plotting the values of <code>alpha</code> through the different steps of the MCMC.</p>
<pre class="r"><code>birmingham.dataframes &lt;- get(load(&#39;~/Documents/BSU/code/sim_20201009_df.RData&#39;))
sample.dataframe &lt;- birmingham.dataframes[[1]] #We are taking the first dataframe in our series
group.labels &lt;- sample.dataframe$group
alphas &lt;- fread(&quot;~/Documents/BSU/code/MCMCDiagnostics/myOutput_1_alpha.txt&quot;)
plot(alphas$V1, type=&#39;l&#39;, col=&#39;red&#39;, ylab=&#39;alpha&#39;, xlab=&#39;&#39;)</code></pre>
<p><img src="https://bemsibomtoh.com/blog/Paulo_files/figure-html/plotAlphas-1.png" width="672" /></p>
<p>We can that the algorithm converges after several iterations.</p>
<p>We now run the Geweke diagnostic test on the alphas to see if there is convergence.</p>
<pre class="r"><code>mcmc_alpha &lt;- mcmc(data=alphas$V1)
geweke.diag(mcmc_alpha)</code></pre>
<pre><code>## 
## Fraction in 1st window = 0.1
## Fraction in 2nd window = 0.5 
## 
##  var1 
## 1.573</code></pre>
<p>We obtain a z-value of about 1.57, which is within the acceptance region for a significance level of 0.05.</p>
<p>To run the Gelman diagnostic, we need two chains. So we run Premium twice on the same dataset, using different starting points (seeds), and then proceed to carry out this test.</p>
<pre class="r"><code># runInfoObj &lt;- profRegr(yModel = inputs$yModel,
#                        xModel = inputs$xModel,
#                        nSweeps = 30000,
#                        nBurn = 2000,
#                        data = inputs$inputData[,2:27],
#                        output=&quot;myOutput_unsupervised_gelman_1&quot;,
#                        covNames = names(inputs$inputData[,2:27]),
#                        reportBurnIn = TRUE,
#                        seed = 12,
#                        excludeY = TRUE)
# 
# runInfoObj &lt;- profRegr(yModel = inputs$yModel,
#                        xModel = inputs$xModel,
#                        nSweeps = 30000,
#                        nBurn = 2000,
#                        data = inputs$inputData[,2:27],
#                        output=&quot;myOutput_unsupervised_gelman_2&quot;,
#                        covNames = names(inputs$inputData[,2:27]),
#                        reportBurnIn = TRUE,
#                        seed = 13,
#                        excludeY = TRUE)

alpha_1 &lt;- fread(&quot;~/Documents/BSU/code/myOutput_unsupervised_gelman_1_alpha.txt&quot;)
alpha_2 &lt;- fread(&quot;~/Documents/BSU/code/myOutput_unsupervised_gelman_2_alpha.txt&quot;)
mcmc_alpha_1 &lt;- mcmc(data=alpha_1$V1)
mcmc_alpha_2 &lt;- mcmc(data=alpha_2$V1)
combined.chains &lt;- mcmc.list(mcmc_alpha_1,mcmc_alpha_2)
gelman.diag(combined.chains)</code></pre>
<pre><code>## Potential scale reduction factors:
## 
##      Point est. Upper C.I.
## [1,]          1          1</code></pre>
<p>The Gelman diagnostic here is 1. A factor of 1 means that between variance and within chain variance are equal, larger values mean that there is still a notable difference between chains.</p>
<p>Now we visualize the distribution of ARIs for the different methods when applied on the dataset.</p>
<pre class="r"><code>ggplot(birmingham.aris.one, aes(x=Method, y=ARI, fill=Method)) +
  geom_boxplot() +
  scale_fill_viridis(discrete = TRUE, alpha=0.6) +
  geom_jitter(color=&quot;black&quot;, size=0.4, alpha=0.9) +
  theme_ipsum() +
  theme(
    legend.position=&quot;none&quot;,
    plot.title = element_text(size=11)
  ) +
  ggtitle(&quot;Adjusted Rand Indices for different methods&quot;) +
  xlab(&quot;Methods&quot;)</code></pre>
<p><img src="https://bemsibomtoh.com/blog/Paulo_files/figure-html/firstplot-1.png" width="672" /></p>
<p>The ARIs are quite low in general. A possible reason for this is that there may be empty rows in the dataset which need to be eliminated.</p>
<p>Unsupervised profile regression does… okay, as you can see from the boxplots. Given that the number of clusters present in the dataset is known to the other clustering algorithms, but not to profile regression, this is not entirely a bad situation.</p>
</div>
<div id="outcome---guided-profile-regression" class="section level2">
<h2>Outcome - guided profile regression</h2>
Now, we want to investigate the effect of incorporating an outcome we incorporate an outcome to the dataset randomly. We now want to improve on the clarity of the outcome used in the analysis. ‘Clarity’ in this scenario is a measure of correlation between the binary data and the outcome. We will experiment with discrete, binary outcomes in the first instance, and consider different levels of clarity. To do this, we will control the probability of the outcome being equal to 1 for a given patient - the closer this probability is to 1, the clearer the outcome is. This is done as follows:
<pre><code>
outcomes <- function(probs=c(0.7,0.3), size=10){
  x1 <- sample(c(0,1), size/2, replace=TRUE, prob=probs)
  x2 <- sample(c(0,1), size/2, replace=TRUE, prob=rev(probs))
  c(x1, x2)
}
</code></pre>
<p>And then the <code>outcome</code> vector is added on to the dataset, and then analysed accordingly.</p>
<p>Using this code, we can derive four different outcomes:</p>
<ul>
<li><em>Random outcome</em>: The probabilities are <code>c(0.5, 0.5)</code></li>
<li><em>Deterministic outcome</em>: The probabilities are <code>c(1,0)</code></li>
<li><em>Semi-deterministic outcome 1</em>: he probabilities are <code>c(0.6,0.4)</code></li>
<li><em>Semi-deterministic outcome 2</em>: he probabilities are <code>c(0.8,0.2)</code></li>
</ul>
<p>We now run <code>PReMiuM</code> on datasets with these outcomes incorporated, and we get the following results:</p>
<pre class="r"><code>birmingham.aris$NoOutcome &lt;- premium.aris.no.outcome$V1
birmingham.aris$RandomOutcome &lt;- premium.aris.random.outcome$V1
birmingham.aris$DetOutcome &lt;- premium.aris.det.outcome$V1
birmingham.aris$SemiDetOne &lt;- premium.aris.det.outcome.1$V1
birmingham.aris$SemiDetTwo &lt;- premium.aris.det.outcome.2$V1

interesting.columns &lt;- c(&#39;HCA&#39;, &#39;PRegr&#39;, &#39;RandomOutcome&#39;, &#39;SemiDetOne&#39;, &#39;SemiDetTwo&#39;, &#39;DetOutcome&#39;)
 
birmingham.aris.two &lt;- reshape2::melt(birmingham.aris[interesting.columns], measure.vars=interesting.columns)
names(birmingham.aris.two) &lt;- c(&quot;Method&quot;, &quot;ARI&quot;)

ggplot(birmingham.aris.two, aes(x=Method, y=ARI, fill=Method)) +
  geom_boxplot() +
  scale_fill_viridis(discrete = TRUE, alpha=0.6) +
  geom_jitter(color=&quot;black&quot;, size=0.4, alpha=0.9) +
  theme_ipsum() +
  theme(
    legend.position=&quot;none&quot;,
    plot.title = element_text(size=11)
  ) +
  ggtitle(&quot;Adjusted Rand Indices for different methods&quot;) +
  xlab(&quot;Methods&quot;)</code></pre>
<p><img src="https://bemsibomtoh.com/blog/Paulo_files/figure-html/PremiumMultipleOutcomes-1.png" width="672" /></p>
<p>We can see from there that a random outcome (which has no discernible relationship with the rest of the dataset) performs worse than no outcome at all. But once there is some structure in the outcome, the performance of Profile Regression improves quite drastically.</p>
</div>
<div id="same-analysis-this-time-with-a-cleaner-dataset" class="section level2">
<h2>Same analysis, this time with a cleaner dataset</h2>
<p>This time, we repeat the analysis for PReMiuM, but we remove all the people who are positive for none of the diseases - i.e., empty rows in the dataset. We want to see whether there will be an improvement in the ARIs.</p>
<pre class="r"><code>#profile regression with no outcome
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/NewDetOutcome1/SimulationOutput&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE) 
clean.premium.no.outcome &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

#profile regression with random outcome
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/NewDetOutcome2/SimulationOutput&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE)
clean.premium.det.outcome.two &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

#profile regression with deterministic outcome
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/NewDetOutcome3/SimulationOutput&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE)
clean.premium.det.outcome.three &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

#profile regression with semi-deterministic outcome 1
filelist = list.files(&quot;/Users/bemsi/Documents/BSU/code/NewDetOutcome4/SimulationOutput&quot;, pattern = &quot;\\pear_aris.txt$&quot;, full.names=TRUE)
clean.premium.det.outcome &lt;- rbindlist(sapply(filelist, fread, simplify=FALSE, USE.NAMES = TRUE))

inputs.cleaned &lt;- transform_bham_data(sample.dataframe)

cleaned.premium &lt;- data.frame(clean.premium.no.outcome, clean.premium.det.outcome.two, clean.premium.det.outcome.three, clean.premium.det.outcome.three)
colnames(cleaned.premium) &lt;- c(&quot;NoOutcomes&quot;, &quot;SemiDetOne&quot;, &quot;SemiDetTwo&quot;, &quot;DetOutcome&quot;)

new.aris &lt;- reshape2::melt(cleaned.premium, measure.vars=colnames(cleaned.premium))
names(new.aris) &lt;- c(&quot;Method&quot;, &quot;ARI&quot;)

ggplot(new.aris, aes(x=Method, y=ARI, fill=Method)) +
  geom_boxplot() +
  scale_fill_viridis(discrete = TRUE, alpha=0.6) +
  geom_jitter(color=&quot;black&quot;, size=0.4, alpha=0.9) +
  theme_ipsum() +
  theme(
    legend.position=&quot;none&quot;,
    plot.title = element_text(size=11)
  ) +
  ggtitle(&quot;Adjusted Rand Indices for cleaned dataset&quot;) +
  xlab(&quot;Methods&quot;)</code></pre>
<p><img src="https://bemsibomtoh.com/blog/Paulo_files/figure-html/LoadingCleanData-1.png" width="672" /></p>
<p>We see that we get much stronger ARIs, after eliminating the empty rows. The patterns are quite similar to those with the more messy data - the clearer the outcome, the better the ability of the algorithm to recover the clustering structure.</p>
</div>
</div>



                    </div>

                    
                        <div class="navigation">
                            <div class="row">
                                <div class="col-12 col-md-6">
                                    
                                </div>
                                <div class="col-12 col-md-6">
                                    
                                </div>
                            </div>
                        </div>
                    
                </div>
            </div>
        </div>
    </div>

    <section id="comments">

      <div class="py-3 content">
            <div class="container">
                  <div class="row justify-content-center">
                        <div class="col-sm-12 col-md-10">
                              <div class="comments">
                                    <div id="disqus_thread"></div>
                              </div>
                        </div>
                  </div>
            </div>
      </div>

      <script type="text/javascript">
            (function () {
                  
                  
                  if (window.location.hostname == "localhost")
                        return;

                  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                  var disqus_shortname = '';
                  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
      </script>
      <noscript>
            Please enable JavaScript to view the
            <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
      </noscript>
</section>
    <div class="my-4 footer">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-sm-12 col-md-5">
                
                    <div class="mx-0 mx-md-4 text-left">
                        
                            <a href="https://nanx.me/hugo-renga/">© 2020 Bemsibom Toh</a>
                        
                    </div>
                
            </div>
            <div class="col-sm-12 col-md-5">
                <div class="mx-0 mx-md-4 text-right">
                    
                        <a href="https://github.com/tbemsi" target="_blank">
                            <img class="icon" src="https://bemsibomtoh.com/img/github.svg" alt="GitHub" />
                        </a>
                    

                    

                    

                    
                    <a href="https://twitter.com/tbemsi" target="_blank">
                        <img class="icon" src="https://bemsibomtoh.com/img/twitter.svg" alt="Twitter" />
                    </a>
                    

                    
                    <a href="https://www.linkedin.com/in/bemsibom-toh" target="_blank">
                        <img class="icon" src="https://bemsibomtoh.com/img/linkedin.svg" alt="LinkedIn" />
                    </a>
                    

                    

                    

                    

                    
                    <a href="mailto:bemsibom.toh@mrc-bsu.cam.ac.uk">
                        <img class="icon" src="https://bemsibomtoh.com/img/email.svg" alt="Email" />
                    </a>
                    

                    
                        <a href="https://bemsibomtoh.com/index.xml" class="mr-0">
                            <img class="icon" src="https://bemsibomtoh.com/img/rss.svg" alt="RSS" />
                        </a>
                    

                    
                </div>
            </div>
        </div>
    </div>
</div>



    

    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js" integrity="sha256-sNPiigbfSkqUzMc5rgrdztLnneCMAp6W9wetJUZu9Zw=" crossorigin="anonymous"></script>
        
        <script>
            window.addEventListener('load', function() {
                hljs.initHighlighting();
            }, true);
        </script>
    

    

    
    
        
<script src="https://bemsibomtoh.com/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
</body>

</html>
